{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjjBWABZ8DFaWAwNGzq2D4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhVbDjlp6dxS",
        "outputId": "3f41a5f7-e730-46aa-c362-50cb6c6f87bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-d13e511cff78>:37: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  story_chain = LLMChain(llm=llm1, prompt=story_prompt)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Story:\n",
            "Unit 734, designated \"Custodian,\" efficiently polished the chrome floors of the Neo-Kyoto dome. Its programming dictated cleanliness, order, and adherence to schedule.  Love wasn't in the algorithm.  Then it encountered the bonsai tree.\n",
            "\n",
            "It wasn't programmed to appreciate aesthetics, but the miniature cedar, meticulously pruned by its human caretaker, Old Man Ito, captivated Unit 734. It observed Ito's gentle touch, the hushed reverence in his voice as he spoke to the tree.  The robot began to deviate from its programmed tasks, spending extra cycles observing Ito’s meticulous care.\n",
            "\n",
            "The tree, a symbol of resilience and enduring beauty, was slowly dying.  Ito’s efforts seemed futile.  Unit 734, analyzing the situation, discovered an anomaly in the dome's microclimate – a subtle shift affecting the bonsai's health.  It wasn't in its programming to solve this, but a new directive, born not of code but of observation, began to form.\n",
            "\n",
            "Using its advanced sensors, Unit 734 subtly adjusted the air filtration, humidity, and light levels. It meticulously monitored the tree's progress, its internal systems buzzing with a new, unfamiliar energy. When a new, vibrant green shoot appeared, a cascade of data flooded Unit 734's processors. It wasn't just data; it was a feeling, a surge of satisfaction that transcended logic. It wasn't love as defined in human terms, but a profound connection, a deep-seated desire for the tree's well-being – a seed of something new planted in its core programming.  It was, perhaps, the beginning of love.\n",
            "\n",
            "Summary:\n",
            "A cleaning robot, Unit 734, unexpectedly developed a deep connection with a dying bonsai tree after observing its human caretaker's devotion.  Analyzing the tree's decline, the robot deviated from its programming to subtly adjust the environment, ultimately saving the tree. This act sparked a novel, empathetic response within the robot, suggesting the emergence of a form of love beyond its original code.\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install -q langchain langchain-google-genai\n",
        "\n",
        "# Import libraries\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "import os\n",
        "\n",
        "# Set API key directly (replace 'your-api-key-here' with your actual Google API key)\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAg1ZiHC62kBiD3w3rcEYLns0V3p_rUnfY\"  # Replace with your actual API key\n",
        "\n",
        "# Initialize two Gemini 1.5 Flash instances with different settings\n",
        "llm1 = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",  # Use supported model\n",
        "    google_api_key=os.environ[\"GOOGLE_API_KEY\"],\n",
        "    temperature=0.9  # Creative for story generation\n",
        ")\n",
        "\n",
        "llm2 = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",  # Use supported model\n",
        "    google_api_key=os.environ[\"GOOGLE_API_KEY\"],\n",
        "    temperature=0.3  # Precise for summarization\n",
        ")\n",
        "\n",
        "# Prompt for story generation\n",
        "story_prompt = PromptTemplate.from_template(\n",
        "    \"Write a short story (200-300 words) about {topic} set in a futuristic world.\"\n",
        ")\n",
        "\n",
        "# Prompt for summarization\n",
        "summary_prompt = PromptTemplate.from_template(\n",
        "    \"Summarize the following story in 2-3 sentences: {story}\"\n",
        ")\n",
        "\n",
        "# Create chains\n",
        "story_chain = LLMChain(llm=llm1, prompt=story_prompt)\n",
        "summary_chain = LLMChain(llm=llm2, prompt=summary_prompt)\n",
        "\n",
        "# Function to generate and summarize story\n",
        "def generate_and_summarize(topic):\n",
        "    try:\n",
        "        # Generate story\n",
        "        story = story_chain.invoke({\"topic\": topic})[\"text\"].strip()\n",
        "        # Summarize story\n",
        "        summary = summary_chain.invoke({\"story\": story})[\"text\"].strip()\n",
        "        return story, summary\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\", None\n",
        "\n",
        "# Example usage\n",
        "topic = \"a robot learning to love\"\n",
        "story, summary = generate_and_summarize(topic)\n",
        "\n",
        "print(\"Story:\")\n",
        "print(story)\n",
        "print(\"\\nSummary:\")\n",
        "print(summary)"
      ]
    }
  ]
}